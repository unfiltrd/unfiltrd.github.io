---
title: "For the Common Good"
layout: "post"
date: "2021-01-08"
categories: 
    - "articles"
author: "Derek Peng"
---
![socialmedia](/images/forthecommongood.jpg)

The other day, a neighbor claimed ANTIFA was behind the Capitol Hill insurrection, not Trump supporters. However, looking through the *New York Times*, *Wall Street Journal*, and other credible news sources, I found zero evidence for this claim. Instead, there were <a href="https://reuters.com/article/uk-factcheck-news-report-antifa-altered/fact-check-news-report-saying-antifa-took-responsibility-for-storming-capitol-is-digitally-altered-idUSKBN29C2ZF">articles</a> proving the exact opposite. I found myself wondering, “how did we get here?”

The answer is social media. Specifically, the viral spread of false information plaguing platforms. The WHO has had to <a href="https://twitter.com/WHO/status/1223904465394249732">dispel</a> alleged coronavirus cures such as eating garlic and drinking bleach. A Facebook post about coronavirus in Malaysia read, “this is an image of one of many ‘Allah’s armies’ sent to attack China,” and was shared over 700 million times. <a href="https://nyti.ms/2Ev9Bd7">Doctored videos</a> of Nancy Pelosi garbled her speech and raised unwarranted questions about her mental aptitude overwhelmed Twitter, facing no consequences. Recently, false claims surrounding the presidential election have stirred conflict and threaten to overthrow democracy. As social media becomes the preferred form of mass communication, regulation of misinformation is essential for the common good.

Each platform creates the algorithms which dictate what each user sees. Because their algorithms are engineered for profit, platforms play a large part in perpetuating misinformation through viral, disputed content and by giving users what they want to hear, even if it’s objectively false. The *New York Times* <a href="https://nyti.ms/2I68vco"> writes</a>, “if they replaced algorithmically tailored and targeted newsfeeds with ones that simply displayed the most recent posts first, the sites would become less enraging—but also less engaging,” and less engaging equals less profit. Even as money-oriented businesses, platforms should be held accountable for their vast influences stemming from their direct involvement in the spread of information.

As always, it is necessary to protect free speech. However, social media platforms are not public forums. As private businesses, it’s well within their rights to regulate their platforms. To ensure consistent unbiased regulations, platforms should create new content standards which specifically address misinformation. Even better, they should adjust their algorithms to give viral posts time to be evaluated by independent fact-checkers, as the Forum for Information and Democracy <a href="https://www.bbc.com/news/technology-54901083">advocates</a>.

Auspiciously, the insurrections of January 6 have emboldened platforms. Trump has been indefinitely <a href="https://washingtonpost.com/technology/2021/01/07/trump-twitter-ban">banned</a> from Twitter, Facebook, and Instagram and removed from Twitch, PayPal, and Shopify. Reddit, YouTube, and Snapchat have added <a href="https://nyti.ms/3orDe4c">limitations</a> on Trump or policies enabling them to suspend accounts for pushing false election claims. <a href="https://nyti.ms/35jgNXp">Parler</a>, a completely unregulated exchange platform, is facing consequences from Google and Apple following its involvement in right-wing conspiracy theories.

By intervening, these companies have entered a slippery slope with the precedents they have set. However, it’s a long overdue and necessary act, forcing platforms to employ a new scrutiny and be held accountable for their immense, ever-growing influences.
